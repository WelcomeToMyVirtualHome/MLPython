{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This section lists some suggestions you may consider when preparing your data for use with\\nLDA.\\n\\x88 Classification Problems. This might go without saying, but LDA is intended for\\nclassification problems where the output variable is categorical. LDA supports both binary\\nand multiclass classification.\\n\\x88 Gaussian Distribution. The standard implementation of the model assumes a Gaussian\\ndistribution of the input variables. Consider reviewing the univariate distributions of each\\nattribute and using transforms to make them more Gaussian-looking (e.g. log and root\\nfor exponential distributions and Box-Cox for skewed distributions).\\n\\x88 Remove Outliers. Consider removing outliers from your data. These can skew the basic\\nstatistics used to separate classes in LDA such the mean and the standard deviation.\\n\\x88 Same Variance. LDA assumes that each input variable has the same variance. It almost\\nalways a good idea to standardize your data before using LDA so that it has a mean of 0\\nand a standard deviation of 1.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This section lists some suggestions you may consider when preparing your data for use with\n",
    "LDA.\n",
    " Classification Problems. This might go without saying, but LDA is intended for\n",
    "classification problems where the output variable is categorical. LDA supports both binary\n",
    "and multiclass classification.\n",
    " Gaussian Distribution. The standard implementation of the model assumes a Gaussian\n",
    "distribution of the input variables. Consider reviewing the univariate distributions of each\n",
    "attribute and using transforms to make them more Gaussian-looking (e.g. log and root\n",
    "for exponential distributions and Box-Cox for skewed distributions).\n",
    " Remove Outliers. Consider removing outliers from your data. These can skew the basic\n",
    "statistics used to separate classes in LDA such the mean and the standard deviation.\n",
    " Same Variance. LDA assumes that each input variable has the same variance. It almost\n",
    "always a good idea to standardize your data before using LDA so that it has a mean of 0\n",
    "and a standard deviation of 1.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= [ 4.20887667  4.01407036  6.24968588  4.17471711  4.41478163  5.01159854\n",
      "  5.47898683  4.90736856  5.74283887  5.89490804 18.73054955 19.99930823\n",
      " 21.11331262 20.22756459 18.43463375 19.04500777 21.09773837 19.58651919\n",
      " 20.46603135 19.45271519]\n",
      "Y= [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_0_size = 10\n",
    "class_1_size = 10\n",
    "num_classes = 2\n",
    "X = np.concatenate((np.random.normal(5,1,class_0_size),np.random.normal(20,1,class_1_size)),axis=0)\n",
    "Y = np.concatenate(([0]*class_0_size,[1]*class_1_size))\n",
    "print(\"X=\",X)\n",
    "print(\"Y=\",Y)\n",
    "colors = ['red','blue']\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(np.arange(0,class_0_size), X[:class_0_size], c='b', label='first')\n",
    "ax1.scatter(np.arange(0,class_1_size), X[class_0_size:], c='r', label='second')\n",
    "plt.legend(loc='center');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_0_mean= 5.0097832487399625  Y_1_mean= 19.815338060887395\n"
     ]
    }
   ],
   "source": [
    "Y_0_mean = np.mean(X[:class_0_size])\n",
    "Y_1_mean = np.mean(X[class_0_size:])\n",
    "print(\"Y_0_mean=\", Y_0_mean, \" Y_1_mean=\",Y_1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma^2= 0.7549953126132676\n"
     ]
    }
   ],
   "source": [
    "P_Y_0 = class_0_size/(class_0_size+class_1_size)\n",
    "P_Y_1 = class_1_size/(class_0_size+class_1_size)\n",
    "\n",
    "X_0_mean = np.mean(X[:class_0_size])\n",
    "X_1_mean = np.mean(X[class_0_size:]);\n",
    "\n",
    "X_0_m_mean = np.subtract(X[:class_0_size],X_0_mean)\n",
    "X_1_m_mean = np.subtract(X[class_0_size:],X_1_mean)\n",
    "variance = np.sum([np.sum(X_0_m_mean**2),np.sum(X_1_m_mean**2)])/(class_0_size+class_1_size-num_classes)\n",
    "print(\"sigma^2=\",variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x, mean, variance, probability):\n",
    "    return np.add(x*mean/variance-mean**2/(2*variance),np.log(probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.61367233   9.321032    24.15549389  10.38700602  11.97995792\n",
      "  15.94014594  19.04150824  15.24852623  20.7923026   21.80135997\n",
      " 106.97246071 115.39132881 122.78332243 116.90592752 105.00890676\n",
      " 109.05905314 122.6799793  112.65226067 118.4882774  111.76440214]\n",
      "[-150.26162173 -155.37443875  -96.69927004 -151.15816141 -144.85751348\n",
      " -129.19366927 -116.92676282 -131.92925234 -110.00179613 -106.01064283\n",
      "  230.86903245  264.16842074  293.40618315  270.15915605  223.10253172\n",
      "  239.12219081  292.99742714  253.33450666  276.41786949  249.8227346 ]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#predictions on training data\n",
    "pred_Y_0 = prediction(X,X_0_mean,variance,P_Y_0)\n",
    "pred_Y_1 = prediction(X,X_1_mean,variance,P_Y_1)\n",
    "print(pred_Y_0)\n",
    "print(pred_Y_1)\n",
    "Y_p = []\n",
    "for y0,y1 in zip(pred_Y_0,pred_Y_1):\n",
    "    if y0 > y1:\n",
    "        Y_p.append(0)\n",
    "    else:\n",
    "        Y_p.append(1)\n",
    "print(Y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.16555689  14.69969976   8.64725296  15.61569804  25.26956898\n",
      "  11.02992636  16.91053419  15.45100159  16.95807168  17.60135131\n",
      " 125.77911647 103.13998223 117.98625794 122.22509572 112.96633575\n",
      " 113.33870303 121.43005107 129.74177691 107.86767329 118.6624827 ]\n",
      "[-152.03406544 -134.10004129 -158.03945615 -130.47696725  -92.29273717\n",
      " -148.61520033 -125.35546502 -131.12839581 -125.16743867 -122.62305645\n",
      "  305.25553246  215.71032143  274.43221767  291.19821321  254.57677676\n",
      "  256.04961164  288.05355051  320.92915591  234.40989223  277.10690869]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#preditions on different dataset\n",
    "X = np.concatenate((np.random.normal(5,1,class_0_size),np.random.normal(20,1,class_1_size)),axis=0)\n",
    "pred_Y_0 = prediction(X,X_0_mean,variance,P_Y_0)\n",
    "pred_Y_1 = prediction(X,X_1_mean,variance,P_Y_1)\n",
    "print(pred_Y_0)\n",
    "print(pred_Y_1)\n",
    "Y_p = []\n",
    "for y0,y1 in zip(pred_Y_0,pred_Y_1):\n",
    "    if y0 > y1:\n",
    "        Y_p.append(0)\n",
    "    else:\n",
    "        Y_p.append(1)\n",
    "print(Y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
